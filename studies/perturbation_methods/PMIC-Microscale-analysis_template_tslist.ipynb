{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWIFT Perturbation Methods Study 2013-11-08 CBL comparison: \n",
    "# Data analysis (template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******\n",
    "##  <font color='darkred'>User Settings:</font>\n",
    "Simulation name and directory, and name of virtual towers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are you using wrfouts ('wrfout') or tslist output ('ts')?\n",
    "model_data_type = 'ts' \n",
    "\n",
    "# Where is the run directory located?\n",
    "modeldatapath = '/glade/scratch/hawbecke/WRF/SWiFT_20131108_PertMethodsGroup/TPert_CBL_18z-20z/'\n",
    "\n",
    "# Where should the processed data be saved?\n",
    "#modelprocessedpath = '/glade/scratch/hawbecke/WRF/SWiFT_20131108_PertMethodsGroup/TPert_CBL_18z-20z/'\n",
    "modelprocessedpath = modeldatapath\n",
    "save_figs = True\n",
    "\n",
    "# Should we compare to observations?\n",
    "compare_to_obs = True\n",
    "# Observation directory location:\n",
    "TTUdata = '/glade/u/home/hawbecke/Research/MMC/Observations/TTU_tilt_corrected_20131108-09.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "####  <font color='darkred'>End User Settings</font>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from scipy import interpolate\n",
    "from netCDF4 import Dataset\n",
    "#import wrf as wrfpy\n",
    "\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "from sklearn import linear_model\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually add a2e-mmc repos to PYTHONPATH if needed\n",
    "import os, sys\n",
    "#sys.path.append('../../../')\n",
    "module_path = os.path.join(os.environ['HOME'],'Code/Python')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from mmctools.plotting import plot_timehistory_at_height, plot_profile, plot_spectrum\n",
    "from mmctools.helper_functions import calc_wind, theta, model4D_calcQOIs, model4D_spatial_spectra, model4D_spatial_cospectra, model4D_spatial_pdfs\n",
    "from mmctools.helper_functions import model4D_spectra, model4D_cospectra, model4D_pdfs, reference_lines\n",
    "from mmctools.wrf.utils import wrfout_seriesReader, tsout_seriesReader, combine_towers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['xtick.labelsize'] = 16\n",
    "mpl.rcParams['ytick.labelsize'] = 16\n",
    "mpl.rcParams['axes.labelsize']  = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using wrfout data:\n",
    "if model_data_type == 'wrfout':\n",
    "    # Specify which wrfout files to use:\n",
    "    modeldatafilter = 'wrfout_d02_2013-11-08_[12][89]:[0-5][0-9]:00'\n",
    "    spectra_dim='ny'\n",
    "    average_dim='datetime'\n",
    "    modelprocessedfile = 'wrfout.nc'\n",
    "    iLocs=[25,40,120,240,300,360,420,480,540,700,900] # downstream locations from which to assess turbulence characteristics versus fetch\n",
    "    \n",
    "# If using tslist output:\n",
    "elif model_data_type == 'ts':\n",
    "    # specify: the names of restart directories (restarts), \n",
    "    #          the start time of the simulation (restart_start),\n",
    "    #          and the domain of interest.\n",
    "    restarts = ['tsout_1800_1830','tsout_1830_1900','tsout_1900_1930','tsout_1930_2000']\n",
    "    restart_start = '2013-11-08 14:00'\n",
    "    domain_of_interest = 'd02'   \n",
    "    spectra_dim='datetime'\n",
    "    average_dim='ny'\n",
    "    modelprocessedfile = 'tsout.nc'\n",
    "    iLocs = np.linspace(0,19,20).astype(int) # downstream locations from which to assess turbulence characteristics versus fetch\n",
    "\n",
    "levels=[5,10,15,30,40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names of output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "simname='PMIC-1_{}'.format(model_data_type)\n",
    "\n",
    "modelprocessedname = '{:s}{:s}.nc'.format(modelprocessedpath,simname)\n",
    "\n",
    "modelprocessedfigure  = 'Microscale_{}_AssessmentMontage120minutes.png'.format(model_data_type)\n",
    "modelprocessedfetch   = 'Microscale_{}_AssessmentFetch120minutes.png'.format(model_data_type)\n",
    "modelprocessedobscomp = 'Microscale_{}_AssessmentObsComparison.png'.format(model_data_type)\n",
    "\n",
    "output_figure  = os.path.join(modelprocessedpath,modelprocessedfigure)\n",
    "output_fetch   = os.path.join(modelprocessedpath,modelprocessedfetch)\n",
    "output_obscomp = os.path.join(modelprocessedpath,modelprocessedobscomp)\n",
    "output_spectra = os.path.join(modelprocessedpath,simname+'_spectra.nc')\n",
    "output_stats   = os.path.join(modelprocessedpath,simname+'_stats.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Load, process 4-D data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Model-specific data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4><font color=\"red\">**Define code-specific reader that returns a standardized xarrays DataSet:**</font></font>\n",
    "\n",
    "- with dimensions `datetime`,`nz`,`ny`,`nx`\n",
    "- with coordinate variables `*datetime`,`x`,`y`,`z`,`zsurface`,`lat`,`lon`\n",
    "- standard column names `u`, `v`, `w`, `theta`,`p`,`wspd`,`wdir`\n",
    "- standard SI units of [m], [m/s], and [K]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. If necessary construct Dataset from raw model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/glade/scratch/hawbecke/WRF/SWiFT_20131108_PertMethodsGroup/TPert_CBL_18z-20z/PMIC-1_ts.nc exists, establishing reference to processed-dataset directly...\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(modelprocessedname):\n",
    "    print('{:s} exists, establishing reference to processed-dataset directly...'.format(modelprocessedname))\n",
    "    ds=xr.open_mfdataset(modelprocessedname,concat_dim='datetime',combine='nested',chunks={'nz': 11})\n",
    "    #CPU times: user 19.7 ms, sys: 1.64 ms, total: 21.4 ms\n",
    "    #Wall time: 21.4 ms     ### JAS note: this is fast because nothing is actually read or loaded into memory (lazy evaluation)\n",
    "else:\n",
    "    if model_data_type == 'wrfout':\n",
    "        print('{:s} does not exist, reading 4-d model outputs and destaggering from wrfout(s)...'.format(modelprocessedname))\n",
    "        ds = wrfout_seriesReader(modeldatapath,modeldatafilter,specified_heights=None)\n",
    "    elif model_data_type == 'ts':\n",
    "        print('{:s} does not exist, reading tslist outputs...'.format(modelprocessedname))\n",
    "        ds = tsout_seriesReader(modeldatapath, restarts, restart_start, domain_of_interest='d02')\n",
    "    #%time ds = wrfout_seriesReader(modeldatapath,modeldatafilter,specified_heights=[4.0, 8.0, 12.0, 20.0, 40.0, 60.0, 80.0, 100.0, 150.0, 200.0])\n",
    "    #CPU times: user 6min 6s, sys: 5min, total: 11min 6s\n",
    "    #Wall time: 13min 4s   ###JAS this was for 60 time instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (datetime: 72000, nx: 20, ny: 10, nz: 88)\n",
       "Coordinates:\n",
       "    zsurface   (ny, nx) float64 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0\n",
       "    lat        (ny, nx) float64 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0\n",
       "    y          (ny, nx) float64 288.0 288.0 288.0 ... 5.472e+03 5.472e+03\n",
       "    lon        (ny, nx) float64 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0\n",
       "    x          (ny, nx) float64 288.0 864.0 1.44e+03 ... 1.066e+04 1.123e+04\n",
       "  * datetime   (datetime) datetime64[ns] 2013-11-08T18:00:00.100000 ... 2013-11-08T20:00:00\n",
       "    z          (datetime, nz, ny, nx) float64 dask.array<chunksize=(72000, 11, 10, 20), meta=np.ndarray>\n",
       "Dimensions without coordinates: nx, ny, nz\n",
       "Data variables:\n",
       "    pr         (datetime, nz, ny, nx) float64 dask.array<chunksize=(72000, 11, 10, 20), meta=np.ndarray>\n",
       "    qv         (datetime, nz, ny, nx) float64 dask.array<chunksize=(72000, 11, 10, 20), meta=np.ndarray>\n",
       "    theta      (datetime, nz, ny, nx) float64 dask.array<chunksize=(72000, 11, 10, 20), meta=np.ndarray>\n",
       "    u          (datetime, nz, ny, nx) float64 dask.array<chunksize=(72000, 11, 10, 20), meta=np.ndarray>\n",
       "    v          (datetime, nz, ny, nx) float64 dask.array<chunksize=(72000, 11, 10, 20), meta=np.ndarray>\n",
       "    w          (datetime, nz, ny, nx) float64 dask.array<chunksize=(72000, 11, 10, 20), meta=np.ndarray>\n",
       "    wspd       (datetime, nz, ny, nx) float64 dask.array<chunksize=(72000, 11, 10, 20), meta=np.ndarray>\n",
       "    wdir       (datetime, nz, ny, nx) float64 dask.array<chunksize=(72000, 11, 10, 20), meta=np.ndarray>\n",
       "    uMean      (datetime, nz, ny, nx) float64 dask.array<chunksize=(72000, 11, 10, 20), meta=np.ndarray>\n",
       "    vMean      (datetime, nz, ny, nx) float64 dask.array<chunksize=(72000, 11, 10, 20), meta=np.ndarray>\n",
       "    wMean      (datetime, nz, ny, nx) float64 dask.array<chunksize=(72000, 11, 10, 20), meta=np.ndarray>\n",
       "    thetaMean  (datetime, nz, ny, nx) float64 dask.array<chunksize=(72000, 11, 10, 20), meta=np.ndarray>\n",
       "    UMean      (datetime, nz, ny, nx) float64 dask.array<chunksize=(72000, 11, 10, 20), meta=np.ndarray>\n",
       "    UdirMean   (datetime, nz, ny, nx) float64 dask.array<chunksize=(72000, 11, 10, 20), meta=np.ndarray>\n",
       "    uu         (datetime, nz, ny, nx) float64 dask.array<chunksize=(72000, 11, 10, 20), meta=np.ndarray>\n",
       "    vv         (datetime, nz, ny, nx) float64 dask.array<chunksize=(72000, 11, 10, 20), meta=np.ndarray>\n",
       "    ww         (datetime, nz, ny, nx) float64 dask.array<chunksize=(72000, 11, 10, 20), meta=np.ndarray>\n",
       "    uv         (datetime, nz, ny, nx) float64 dask.array<chunksize=(72000, 11, 10, 20), meta=np.ndarray>\n",
       "    uw         (datetime, nz, ny, nx) float64 dask.array<chunksize=(72000, 11, 10, 20), meta=np.ndarray>\n",
       "    vw         (datetime, nz, ny, nx) float64 dask.array<chunksize=(72000, 11, 10, 20), meta=np.ndarray>\n",
       "    wth        (datetime, nz, ny, nx) float64 dask.array<chunksize=(72000, 11, 10, 20), meta=np.ndarray>\n",
       "    UU         (datetime, nz, ny, nx) float64 dask.array<chunksize=(72000, 11, 10, 20), meta=np.ndarray>\n",
       "    Uw         (datetime, nz, ny, nx) float64 dask.array<chunksize=(72000, 11, 10, 20), meta=np.ndarray>\n",
       "    TKE        (datetime, nz, ny, nx) float64 dask.array<chunksize=(72000, 11, 10, 20), meta=np.ndarray>\n",
       "Attributes:\n",
       "    SIMULATION_START_DATE:  2013-11-08 14:00\n",
       "    DX:                     12.0\n",
       "    DY:                     12.0\n",
       "    CREATED_FROM:           /glade/scratch/hawbecke/WRF/SWiFT_20131108_PertMe...\n",
       "    MEAN_OPT:               lowess\n",
       "    WINDOW_SIZE:            18000\n",
       "    LOWESS_DELTA:           18000.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Calculation of spanwise mean and perturbations for all streamwise locations and all variables of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.path.exists(modelprocessedname):\n",
    "    print('{:s} exists, skipping calculation of quantities of interest...'.format(modelprocessedname))\n",
    "else:\n",
    "    print('{:s} does not exist, calculating of quantities of interest...'.format(modelprocessedname))\n",
    "    if model_data_type == 'wrfout':\n",
    "        ds=model4D_calcQOIs(ds,'ny',data_type=model_data_type)\n",
    "    elif model_data_type == 'ts':\n",
    "        ds=model4D_calcQOIs(ds,'datetime',data_type=model_data_type,mean_opt='lowess',lowess_delta=18000.0)\n",
    "    #CPU times: user 3min 3s, sys: 8min 20s, total: 11min 24s\n",
    "    #Wall time: 17min 37s ###JAS this was for 60 time instances\n",
    "    print(ds)\n",
    "#### So here is the processed dataset...\n",
    "#ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure to check the mean:\n",
    "If you are interested in seeing how the means look, change this block to 'code'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    #%%time\n",
    "    fig,ax = plt.subplots(nrows=4,figsize=(16,12),sharex=True)\n",
    "    print('starting...')\n",
    "    ds.u.isel(nz=15,ny=5,nx=14).plot(ax=ax[0],lw=2.0,c='k',alpha=0.5)\n",
    "    ds.uMean.isel(nz=15,ny=5,nx=14).plot(ax=ax[0],lw=3.0,c='blue')\n",
    "    ax[0].plot(ds.datetime,np.ones(ds.datetime.size)*np.mean(ds.u.isel(nz=15,ny=5,nx=14).data),c='darkred',lw=2.0)\n",
    "    ax[0].set_xlabel('')\n",
    "    print('1 done')\n",
    "    ds.isel(nz=15,ny=5,nx=14).v.plot(ax=ax[1],lw=2.0,c='k',alpha=0.5)\n",
    "    ds.isel(nz=15,ny=5,nx=14).vMean.plot(ax=ax[1],lw=2.0,c='blue')\n",
    "    ax[1].plot(ds.datetime,np.ones(ds.datetime.size)*np.mean(ds.v.isel(nz=15,ny=5,nx=14).data),c='darkred',lw=2.0)\n",
    "    ax[1].set_xlabel('')\n",
    "    print('2 done')\n",
    "    ds.isel(nz=15,ny=5,nx=14).w.plot(ax=ax[2],lw=2.0,c='k',alpha=0.5)\n",
    "    ds.isel(nz=15,ny=5,nx=14).wMean.plot(ax=ax[2],lw=2.0,c='blue')\n",
    "    ax[2].plot(ds.datetime,np.ones(ds.datetime.size)*np.mean(ds.w.isel(nz=15,ny=5,nx=14).data),c='darkred',lw=2.0)\n",
    "    ax[2].set_xlabel('')\n",
    "    print('3 done')\n",
    "    ds.isel(nz=15,ny=5,nx=14).theta.plot(ax=ax[3],lw=2.0,c='k',alpha=0.5)\n",
    "    ds.isel(nz=15,ny=5,nx=14).thetaMean.plot(ax=ax[3],lw=2.0,c='blue')\n",
    "    ax[3].plot(ds.datetime,np.ones(ds.datetime.size)*np.mean(ds.theta.isel(nz=15,ny=5,nx=14).data),c='darkred',lw=2.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Save full processed dataset, if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveProcessedDataSetSwitch=True\n",
    "\n",
    "if os.path.exists(modelprocessedname):\n",
    "    print('{:s} exists, no need to save...'.format(modelprocessedname))\n",
    "else:\n",
    "    if saveProcessedDataSetSwitch:\n",
    "        ds.to_netcdf(modelprocessedname, mode='w', format='NETCDF4', unlimited_dims='datetime', compute=True)\n",
    "        #CPU times: user 1.34 s, sys: 1min 48s, total: 1min 50s\n",
    "        #Wall time: 5min 23s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check to see if spectra / cospectra / PDF have already been calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(output_spectra):\n",
    "    print('{:s} exists, no need to calculate spectra / cospectra...'.format(output_spectra))\n",
    "    calc_spectra = False\n",
    "    spectra_ds=xr.open_dataset(output_spectra)\n",
    "else:\n",
    "    print(\"doesn't exist... going to calculate spectra and cospectra...\")\n",
    "    calc_spectra = True\n",
    "    \n",
    "if os.path.exists(output_stats):\n",
    "    print('{:s} exists, no need to calculate PDF...'.format(output_stats))\n",
    "    calc_stats = False\n",
    "    stats_ds=xr.open_dataset(output_stats)\n",
    "else:\n",
    "    print(\"doesn't exist... going to calculate spectra and cospectra...\")\n",
    "    calc_stats = True\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate windspeed-based spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For tslist output this can take around 30 minutes per level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "if calc_spectra:\n",
    "    vertLevels=[15]\n",
    "    fld='wspd' #'theta'\n",
    "    fldMean='UMean' #'thetaMean'\n",
    "    print('calculating spectra of {}'.format(fld))\n",
    "    f, Puuf = model4D_spectra(ds,spectra_dim=spectra_dim,average_dim=average_dim,\n",
    "                              vert_levels=vertLevels,horizontal_locs=iLocs,\n",
    "                              fld=fld,fldMean=fldMean)\n",
    "\n",
    "    ##Past-timing\n",
    "    #CPU times: user 2 s, sys: 1.32 s, total: 3.31 s\n",
    "    #Wall time: 17.9 s\n",
    "    ##New-timing: From 60-time instance reload of the full procesed datafile\n",
    "    #CPU times: user 1.49 s, sys: 184 ms, total: 1.67 s\n",
    "    #Wall time: 4.42 s\n",
    "else:\n",
    "    print('spectra already calculated...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate cospectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "if calc_spectra:\n",
    "    vertLevels=[15]\n",
    "    fld0 = 'wspd'; fld0Mean = 'UMean' \n",
    "    fld1 = 'w'; fld1Mean = 'wMean' \n",
    "    print('calculating cospectra of {} and {}'.format(fld0,fld1))\n",
    "    f, Puwf = model4D_cospectra(ds,spectra_dim=spectra_dim,average_dim=average_dim,\n",
    "                                vert_levels=vertLevels,horizontal_locs=iLocs,\n",
    "                                fldv0=fld0,fldv0Mean=fld0Mean,fldv1=fld1,fldv1Mean=fld1Mean)\n",
    "\n",
    "    fld0 = 'w'; fld0Mean = 'wMean'\n",
    "    fld1 = 'theta'; fld1Mean = 'thetaMean'\n",
    "    print('calculating cospectra of {} and {}'.format(fld0,fld1))\n",
    "    f, Pwtf = model4D_cospectra(ds,spectra_dim=spectra_dim,average_dim=average_dim,\n",
    "                                vert_levels=vertLevels,horizontal_locs=iLocs,\n",
    "                                fldv0=fld0,fldv0Mean=fld0Mean,fldv1=fld1,fldv1Mean=fld1Mean)\n",
    "else:\n",
    "    print('cospectra already calculated...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate w-perturbation distribution and distribution higher-order moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#from scipy.stats import skew,kurtosis\n",
    "if calc_stats:\n",
    "    bins_vector = np.linspace(-5.0,5.0,240)\n",
    "    fld='w' #'theta'\n",
    "    fldMean='wMean' #'thetaMean'\n",
    "    print('Calculating PDF of {}'.format(fld))\n",
    "    hist_cum, bin_edges, sk_vec, kurt_vec = model4D_pdfs(ds,'ny',vertLevels,iLocs,fld,fldMean,bins_vector)\n",
    "\n",
    "    ##Past-timing\n",
    "    #CPU times: user 1min 42s, sys: 2min 16s, total: 3min 59s\n",
    "    #Wall time: 8min 3s\n",
    "    ##New-timing: From 60-time instance reload of the full procesed datafile\n",
    "    #CPU times: user 37.6 s, sys: 1min 54s, total: 2min 31s\n",
    "    #Wall time: 2min 44s\n",
    "    ##Newest-timing: From 120-time instance reload of the full procesed datafile\n",
    "    #Accumulating statistics over 120 time-instances\n",
    "    #CPU times: user 8.8 s, sys: 2.35 s, total: 11.1 s\n",
    "    #Wall time: 19.6 s\n",
    "else:\n",
    "    print('stats already calculated...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create xarray datasets for the spectra and distrbution metrics, then save them to file for sharing amongst the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calc_spectra: spectra_ds = xr.Dataset()\n",
    "if calc_stats: stats_ds = xr.Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calc_spectra:\n",
    "    spectra_dims_dict = {\n",
    "            'dim_0':'vert_levels',\n",
    "            'dim_1':'x',\n",
    "            'dim_2': 'f',\n",
    "    }\n",
    "    spectra_ds['Puuf'] = xr.DataArray(Puuf)\n",
    "    spectra_ds['Puwf'] = xr.DataArray(Puwf)\n",
    "    spectra_ds['f'] = xr.DataArray(np.squeeze(f),dims=['dim_2'])\n",
    "    spectra_ds = spectra_ds.assign_coords(f=spectra_ds['f'])\n",
    "    spectra_ds = spectra_ds.assign_coords(f=spectra_ds['f'])\n",
    "    spectra_ds = spectra_ds.rename_dims(spectra_dims_dict)   \n",
    "    spectra_ds.attrs['vert_level'] = vertLevels[0]\n",
    "    spectra_ds['iLocs'] = xr.DataArray(iLocs,dims=['x'])\n",
    "\n",
    "if calc_stats:\n",
    "    stats_dims_dict = {\n",
    "            'dim_0':'vert_levels',\n",
    "            'dim_1':'x',\n",
    "            'dim_2': 'bins',\n",
    "    }\n",
    "    stats_ds['hist_cum']=xr.DataArray(hist_cum)\n",
    "    stats_ds['bins']=xr.DataArray(bins_vector[:-1]+np.diff(bins_vector)/2.0,dims=['dim_2'])\n",
    "    stats_ds['sk_vec']=xr.DataArray(sk_vec,dims=['dim_0','dim_1'])\n",
    "    stats_ds['kurt_vec']=xr.DataArray(kurt_vec,dims=['dim_0','dim_1'])\n",
    "    stats_ds = stats_ds.assign_coords(bins=stats_ds['bins'])\n",
    "    stats_ds.attrs['vert_level'] = vertLevels[0]\n",
    "    stats_ds['iLocs'] = xr.DataArray(iLocs,dims=['x'])\n",
    "    \n",
    "    if model_data_type == 'wrfout':\n",
    "        stats_ds = stats_ds.assign_coords(x=ds['x'].isel(nx=iLocs).values)\n",
    "    elif model_data_type == 'ts':\n",
    "        stats_ds = stats_ds.assign_coords(x=ds['x'].isel(nx=iLocs,ny=0).values)\n",
    "    stats_ds = stats_ds.rename_dims(stats_dims_dict)\n",
    "print(spectra_ds)\n",
    "print(stats_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calc_spectra: spectra_ds.to_netcdf(output_spectra, mode='w', format='NETCDF4', compute=True)\n",
    "print(output_spectra)\n",
    "if calc_stats: stats_ds.to_netcdf(output_stats, mode='w', format='NETCDF4', compute=True)\n",
    "print(output_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create montage simulation summary figure of instantaneous windspeed, windspeed energy spectra, cospectra, and w-perturbation distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "fntSize = 16\n",
    "vertLevel = spectra_ds.vert_level\n",
    "datetime_to_plot = 2\n",
    "\n",
    "if model_data_type == 'wrfout': spec_y_lim = [1e-1,1e5]\n",
    "if model_data_type == 'ts': spec_y_lim = [1e-5,1e5]\n",
    "\n",
    "###Try using grispec to layout multiple plots in a single plot frame....\n",
    "fig = plt.figure(figsize=(34,len(iLocs)*4))\n",
    "gs=GridSpec(len(iLocs)*4,34)\n",
    "if model_data_type == 'wrfout': iLocs = spectra_ds.iLocs.data\n",
    "if model_data_type == 'ts': iLocs = spectra_ds.iLocs.data[1::2]\n",
    "ax=[]\n",
    "cnt_i=0\n",
    "for iLoc in iLocs:\n",
    "    ax.append(fig.add_subplot(gs[cnt_i*4:(cnt_i+1)*4-1,17:34]))   #The histograms\n",
    "    print('ax[{:d}] setup complete...'.format(cnt_i))\n",
    "    cnt_i=cnt_i+1\n",
    "numLeftColumnPlots = 6\n",
    "axhgt = np.floor(((len(iLocs)+1)*4-1)/(numLeftColumnPlots+2)).astype(int)\n",
    "print(0*axhgt,numLeftColumnPlots*axhgt)\n",
    "ax.append(fig.add_subplot(gs[0*axhgt:2*axhgt-1,0:15]))  # The pcolormesh with overlayed lines of fetch\n",
    "axpc=cnt_i\n",
    "print('ax[{:d}] setup complete...'.format(axpc))\n",
    "cnt_i=cnt_i+1\n",
    "ax.append(fig.add_subplot(gs[2*axhgt:4*axhgt-1,0:15]))  # The spectra plot\n",
    "axsp=cnt_i\n",
    "print('ax[{:d}] setup complete...'.format(axsp))\n",
    "cnt_i=cnt_i+1\n",
    "\n",
    "\n",
    "if model_data_type == 'wrfout':\n",
    "    x_plt = ds.x.isel(nx=spectra_ds.iLocs.data)/1e3\n",
    "elif model_data_type == 'ts':\n",
    "    x_plt = ds.x.isel(nx=spectra_ds.iLocs.data,ny=0)/1e3\n",
    "        \n",
    "bins_vector = np.zeros((stats_ds.bins.size+1))\n",
    "bins_vector[:-1] = stats_ds.bins.data - (stats_ds.bins[1]-stats_ds.bins[0]).data/2.0\n",
    "bins_vector[-1] = stats_ds.bins.data[-1] + (stats_ds.bins[1]-stats_ds.bins[0]).data/2.0\n",
    "\n",
    "flux_vs_fetch=False\n",
    "if flux_vs_fetch:\n",
    "    ax.append(fig.add_subplot(gs[4*axhgt:5*axhgt-1,0:15]))  # The TKE vs. fetch plot\n",
    "    axTKE=cnt_i\n",
    "    print('ax[{:d}] setup complete...'.format(axTKE))\n",
    "    cnt_i=cnt_i+1\n",
    "    ax.append(fig.add_subplot(gs[5*axhgt:6*axhgt-1,0:15]))  # The <U'w'> vs. fetch plot\n",
    "    axUw=cnt_i\n",
    "    print('ax[{:d}] setup complete...'.format(axUw))\n",
    "    cnt_i=cnt_i+1\n",
    "    ax.append(fig.add_subplot(gs[6*axhgt:7*axhgt-1,0:15]))  # The <w'th'> vs. fetch plot\n",
    "    axwth=cnt_i\n",
    "    print('ax[{:d}] setup complete...'.format(axwth))\n",
    "    cnt_i=cnt_i+1\n",
    "    ax.append(fig.add_subplot(gs[7*axhgt:8*axhgt-1,0:15]))  # The stats plot\n",
    "    axst=cnt_i\n",
    "    print('ax[{:d}] setup complete...'.format(axst))\n",
    "    cnt_i=cnt_i+1\n",
    "else:\n",
    "    ax.append(fig.add_subplot(gs[4*axhgt:6*axhgt-1,0:15]))  # The stats plot\n",
    "    axcosp=cnt_i\n",
    "    print('ax[{:d}] setup complete...'.format(axcosp))\n",
    "    cnt_i=cnt_i+1\n",
    "    ax.append(fig.add_subplot(gs[6*axhgt:8*axhgt-1,0:15]))  # The stats plot\n",
    "    axst=cnt_i\n",
    "    print('ax[{:d}] setup complete...'.format(axst))\n",
    "    cnt_i=cnt_i+1\n",
    "\n",
    "########----  Multiple time instance histogram for each fetch-wise location in iLocs\n",
    "n = len(iLocs)\n",
    "colors = plt.cm.jet(np.linspace(0,1,n))\n",
    "cnt_lvl=0\n",
    "cnt_i=0\n",
    "props = dict(boxstyle='square', facecolor='wheat', alpha=0.5)  #Properties for text boxes\n",
    "for iLoc in iLocs:\n",
    "    if model_data_type == 'wrfout':\n",
    "        x_str = ds['x'].isel(nx=iLoc).values/1e3\n",
    "    elif model_data_type == 'ts':\n",
    "        x_str = ds['x'].isel(nx=iLoc,ny=0).values/1e3\n",
    "    max_histval = np.amax(stats_ds.hist_cum[cnt_lvl,cnt_i,:]/(ds.dims['datetime']*ds.dims['ny']))\n",
    "    ax[cnt_i].grid(zorder=0)\n",
    "    ### bins_vector[:-1] and bin_edges are equivalent\n",
    "    im=ax[cnt_i].bar(bins_vector[:-1]+np.diff(bins_vector)/2, stats_ds.hist_cum[cnt_lvl,cnt_i,:]/(ds.dims['datetime']*ds.dims['ny']), \n",
    "                     width=np.diff(bins_vector),color=colors[cnt_i], ec=\"k\", align=\"edge\",zorder=3)\n",
    "    textstr ='At x = {:6.2f} km:\\n skewness = {:4.2f},\\n kurtosis = {:4.2f}'.format(x_str,\n",
    "                                                                                stats_ds.sk_vec[cnt_lvl,cnt_i].data,\n",
    "                                                                                stats_ds.kurt_vec[cnt_lvl,cnt_i].data)\n",
    "    ax[cnt_i].text(0.80, 0.95, textstr, transform=ax[cnt_i].transAxes, fontsize=16,verticalalignment='top', bbox=props)\n",
    "    ax[cnt_i].set_ylim(0.0,max_histval)\n",
    "    ax[cnt_i].set_ylim(0.0,max_histval)\n",
    "    if(cnt_i is len(iLocs)-1):\n",
    "        ax[cnt_i].set_xlabel(r'$w`$ $[\\mathrm{ms^{-1}}]$',fontsize=fntSize)\n",
    "    cnt_i=cnt_i+1\n",
    "\n",
    "########----  The pcolormesh and overlayed fetch lines plot\n",
    "if model_data_type == 'wrfout':\n",
    "    im = ax[axpc].pcolormesh(ds.x/1e3,ds.y/1e3,\n",
    "                        ds['wspd'].isel(datetime=datetime_to_plot,nz=vertLevel)-ds['UMean'].isel(datetime=datetime_to_plot,nz=vertLevel),\n",
    "                        zorder=1,cmap=plt.cm.coolwarm,vmin=-3, vmax=3)\n",
    "elif model_data_type == 'ts':\n",
    "    wrfout = xr.open_dataset(sorted(glob.glob('{}wrfout_d02*'.format(modeldatapath), recursive=True))[-1])\n",
    "    wrf_u = wrfout.U.isel(Time=0,bottom_top=vertLevel).data\n",
    "    wrf_v = wrfout.V.isel(Time=0,bottom_top=vertLevel).data\n",
    "\n",
    "    wrf_u = (wrf_u[:,1:] + wrf_u[:,:-1])*0.5\n",
    "    wrf_v = (wrf_v[1:,:] + wrf_v[:-1,:])*0.5\n",
    "    wrf_vel = (wrf_u**2 + wrf_v**2)**0.5\n",
    "    im = ax[axpc].pcolormesh(wrfout.west_east*wrfout.DX/1e3, wrfout.south_north*wrfout.DY/1e3,\n",
    "                    wrf_vel-np.mean(wrf_vel,axis=0),\n",
    "                    zorder=1,cmap=plt.cm.coolwarm,vmin=-3, vmax=3)\n",
    "ax[axpc].set_title('Windspeed at vertical level k = {:d}'.format(vertLevel),fontsize=fntSize)\n",
    "ax[axpc].set_ylabel(r'$y$ $[\\mathrm{km}]$',fontsize=fntSize)\n",
    "ax[axpc].set_xlabel(r'$x$ $[\\mathrm{km}]$',fontsize=fntSize)\n",
    "fig.colorbar(im, ax=ax[axpc], orientation='horizontal',pad=0.15)\n",
    "\n",
    "colors = plt.cm.jet(np.linspace(0,1,n))\n",
    "cnt_i=0\n",
    "for iLoc in iLocs: \n",
    "    im=ax[axpc].plot(ds.x.isel(nx=iLoc).values/1e3*np.ones(len(ds.y)),ds.y/1e3,'-',linewidth=4,color=colors[cnt_i],label='iLoc')\n",
    "    cnt_i=cnt_i+1\n",
    "\n",
    "########----  The spectra versus fetch plot\n",
    "if model_data_type == 'wrfout':\n",
    "    xRng = [1.0e-2,4e-1]\n",
    "    y_intercept = 1e4  # starting point for ref lines\n",
    "elif model_data_type == 'ts':\n",
    "    xRng = [1.0e-2,4e-1]\n",
    "    y_intercept = 1e4  # starting point for ref lines\n",
    "slopes = np.asarray([-5/3,-1])  # reference slope list\n",
    "ref_ls = ['-.','--']\n",
    "slope_str = ['-5/3','-1']\n",
    "yRng = reference_lines(xRng , y_intercept, slopes)\n",
    "props = dict(boxstyle='square', facecolor='white', alpha=1.0)  #Properties for text boxes\n",
    "for ss, slope in enumerate(slopes):\n",
    "    ax[axsp].plot(xRng, yRng[:,ss], ls=ref_ls[ss], c='k') \n",
    "    ax[axsp].text(xRng[-1], yRng[-1,ss], slope_str[ss], fontsize=16, va='center', ha='center', bbox=props)\n",
    "    \n",
    "n = len(iLocs)\n",
    "colors = plt.cm.jet(np.linspace(0,1,n))\n",
    "\n",
    "cnt_i=0\n",
    "for iLoc in iLocs:\n",
    "    if model_data_type == 'wrfout':\n",
    "        x_str = ds['x'].isel(nx=iLoc).values/1e3\n",
    "    elif model_data_type == 'ts':\n",
    "        x_str = ds['x'].isel(nx=iLoc,ny=0).values/1e3\n",
    "\n",
    "    ax[axsp].loglog(spectra_ds.f, spectra_ds.Puuf[:,cnt_i,:].transpose(),'-',color=colors[cnt_i],label='x = {:6.2f} km'.format(x_str))\n",
    "    cnt_i = cnt_i + 1\n",
    "ax[axsp].grid()\n",
    "ax[axsp].set_title('Spectra at vertical level k = {:d}'.format(spectra_ds.vert_level),fontsize=fntSize)\n",
    "\n",
    "ax[axsp].set_ylim(spec_y_lim)\n",
    "if model_data_type == 'wrfout':\n",
    "    ax[axsp].set_ylabel(r'$E_{uu}(k)$',fontsize=fntSize)\n",
    "    ax[axsp].set_xlabel(r'$k$',fontsize=fntSize)\n",
    "elif model_data_type == 'ts':\n",
    "    ax[axsp].set_ylabel(r'$E_{uu}(f)$',fontsize=fntSize)\n",
    "    ax[axsp].set_xlabel(r'$f$',fontsize=fntSize)\n",
    "ax[axsp].legend(loc='lower left',prop=dict(size=fntSize))\n",
    "\n",
    "\n",
    "if flux_vs_fetch:\n",
    "    ########----  The TKE, <U'w'>, and <w'th'> fetch plot\n",
    "    n = len(levels)\n",
    "    colors = plt.cm.gnuplot(np.linspace(0,1,n))\n",
    "    cnt_k=0\n",
    "    for lev in levels:\n",
    "        ax[axTKE].plot(ds.x/1e3,ds['TKE'].sel(nz=lev).mean('ny').mean('datetime').transpose(),\n",
    "                       color=colors[cnt_k],\n",
    "                       label='z ~{:6.2f} m AGL'.format(ds['z'].isel(datetime=0,nz=lev,ny=0,nx=0).values))\n",
    "        ax[axTKE].set_xlabel(r'$x$ $[\\mathrm{km}]$',fontsize=fntSize)\n",
    "        ax[axUw].plot(ds.x/1e3,ds['Uw'].sel(nz=lev).mean('ny').mean('datetime').transpose(),color=colors[cnt_k])\n",
    "        ax[axUw].set_xlabel(r'$x$ $[\\mathrm{km}]$',fontsize=fntSize)\n",
    "        ax[axwth].plot(ds.x/1e3,ds['wth'].sel(nz=lev).mean('ny').mean('datetime').transpose(),color=colors[cnt_k])\n",
    "        ax[axwth].set_xlabel(r'$x$ $[\\mathrm{km}]$',fontsize=fntSize)\n",
    "        cnt_k = cnt_k+1\n",
    "    ax[axTKE].legend(loc='lower center',fontsize=fntSize)\n",
    "else:\n",
    "    ########----  The cospectra versus fetch plot\n",
    "    if model_data_type == 'wrfout':\n",
    "        xRng = [1.0e-2,4e-1]\n",
    "        y_intercept = 1e4  # starting point for ref lines\n",
    "    elif model_data_type == 'ts':\n",
    "        xRng = [1.0e-2,4e-1]\n",
    "        y_intercept = 3e4  # starting point for ref lines\n",
    "    slopes = np.asarray([-7/3,-5/3,-1])  # reference slope list\n",
    "    ref_ls = ['-','-.','--']\n",
    "    slope_str = ['-7/3','-5/3','-1']\n",
    "    yRng = reference_lines(xRng , y_intercept, slopes)\n",
    "\n",
    "    props = dict(boxstyle='square', facecolor='white', alpha=1.0)  #Properties for text boxes\n",
    "    for ss, slope in enumerate(slopes):\n",
    "        ax[axcosp].plot(xRng, yRng[:,ss], ls=ref_ls[ss], c='k')  \n",
    "        ax[axcosp].text(xRng[-1], yRng[-1,ss], slope_str[ss], fontsize=16, va='center', ha='center', bbox=props)\n",
    "\n",
    "    n = len(iLocs)\n",
    "    colors = plt.cm.jet(np.linspace(0,1,n))\n",
    "    cnt_i=0\n",
    "    for iLoc in iLocs:\n",
    "        if model_data_type == 'wrfout':\n",
    "            x_str = ds['x'].isel(nx=iLoc).values/1e3\n",
    "        elif model_data_type == 'ts':\n",
    "            x_str = ds['x'].isel(nx=iLoc,ny=0).values/1e3\n",
    "\n",
    "        ax[axcosp].loglog(spectra_ds.f, spectra_ds.Puwf[:,cnt_i,:].transpose(),'-',color=colors[cnt_i],label='x = {:6.2f} km'.format(x_str))\n",
    "        cnt_i = cnt_i + 1\n",
    "    ax[axcosp].grid()\n",
    "    #print('k-lowest = {:f}'.format(f[0]*(ds.dims['south_north']*ds.attrs['DX'])))\n",
    "    #print('k-highest = {:f}'.format(f[-1]*(ds.dims['south_north']*ds.attrs['DX'])))\n",
    "    #print('series length = {:d}'.format(nblock))\n",
    "    #ax[axcosp].set_ylim([1e-5,1e6])\n",
    "    ax[axcosp].set_ylim(spec_y_lim)\n",
    "    if model_data_type == 'wrfout':\n",
    "        ax[axcosp].set_ylabel(r'$E_{uw}(k)$',fontsize=fntSize)\n",
    "        ax[axcosp].set_xlabel(r'$k$',fontsize=fntSize)\n",
    "    elif model_data_type == 'ts':\n",
    "        ax[axcosp].set_ylabel(r'$E_{uw}(f)$',fontsize=fntSize)\n",
    "        ax[axcosp].set_xlabel(r'$f$',fontsize=fntSize)\n",
    "    ax[axcosp].legend(loc='lower left',prop=dict(size=fntSize))\n",
    "\n",
    "########----  The stats versus fetch plot\n",
    "ax[axst].plot(x_plt,stats_ds.sk_vec[cnt_lvl,:],'o-',color='b',label='skewness')\n",
    "ax[axst].plot(x_plt,stats_ds.kurt_vec[cnt_lvl,:],'o-',color='r',label='kurtosis')\n",
    "ax[axst].set_xlabel(r'$x$ $[\\mathrm{km}]$',fontsize=fntSize)\n",
    "ax[axst].legend(loc='upper right',fontsize=fntSize)\n",
    "ax[axst].plot(x_plt,np.zeros(x_plt.shape),'--',color='k',label='skewness = 0 (symmetric), kurtosis = 0 (normal)')\n",
    "\n",
    "if save_figs:\n",
    "    print(output_figure)\n",
    "    fig.savefig(output_figure,dpi=200)\n",
    "##Past-timing\n",
    "#CPU times: user 3.9 s, sys: 7.3 s, total: 11.2 s\n",
    "#Wall time: 2min 4s  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create TKE, momentum flux, and sensible heat flux versus fetch figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,1, figsize=(24, 36), sharex=True)\n",
    "axTKE=0\n",
    "axUw=1\n",
    "axwth=2\n",
    "########----  The TKE, <U'w'>, and <w'th'> fetch plot\n",
    "n = len(levels)\n",
    "colors = plt.cm.gnuplot(np.linspace(0,1,n))\n",
    "cnt_k=0\n",
    "\n",
    "\n",
    "if model_data_type == 'wrfout':\n",
    "    x_plt = ds.x/1e3\n",
    "elif model_data_type == 'ts':\n",
    "    x_plt = ds.x.isel(ny=0)/1e3\n",
    "    \n",
    "for cnt_k,lev in enumerate(levels):\n",
    "    ax[axTKE].plot(x_plt,ds['TKE'].sel(nz=lev).mean('datetime').mean('ny').transpose(),\n",
    "                   color=colors[cnt_k],\n",
    "                   label='z ~{:6.2f} m AGL'.format(ds['z'].isel(datetime=0,nz=lev,ny=0,nx=0).values))\n",
    "    ax[axTKE].set_xlabel(r'$x$ $[\\mathrm{km}]$',fontsize=fntSize)\n",
    "    ax[axTKE].set_ylabel(r'$TKE$ $[\\mathrm{m^2 s^{-2}}]$',fontsize=fntSize)\n",
    "    ax[axUw].plot(x_plt,ds['Uw'].sel(nz=lev).mean('datetime').mean('ny').transpose(),color=colors[cnt_k])\n",
    "    ax[axUw].set_xlabel(r'$x$ $[\\mathrm{km}]$',fontsize=fntSize)\n",
    "    ax[axUw].set_ylabel(r'$<Uw>$ $[\\mathrm{m^2 s^{-2}}]$',fontsize=fntSize)\n",
    "    ax[axwth].plot(x_plt,ds['wth'].sel(nz=lev).mean('datetime').mean('ny').transpose(),color=colors[cnt_k])\n",
    "    ax[axwth].set_xlabel(r'$x$ $[\\mathrm{km}]$',fontsize=fntSize)\n",
    "    ax[axwth].set_ylabel(r'$<w\\theta>$ $[\\mathrm{Km s^{-1}}]$',fontsize=fntSize)\n",
    "    ax[axTKE].legend(loc='lower center',fontsize=fntSize)\n",
    "if save_figs:\n",
    "    print(output_fetch)\n",
    "    fig.savefig(output_fetch,dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare microscale domains mean-profiles to observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compare_to_obs:\n",
    "    df = pd.read_csv(TTUdata, parse_dates=True, index_col='datetime')\n",
    "    # Calculate wind speed and direction\n",
    "    df['wspd'], df['wdir'] = calc_wind(df)\n",
    "    # Calculate potential temperature\n",
    "    df['theta'] = theta(df['T'],df['p'])\n",
    "    df30 = df.pivot(columns='height',values=['u','v','w','wspd','wdir','theta']).resample('30min').mean().stack()\n",
    "    df30.reset_index(inplace=True)\n",
    "    df30.set_index(['datetime'],inplace=True)\n",
    "    obs_legStrs = []\n",
    "    mod_legStrs = []\n",
    "    datetimeStrs = []\n",
    "    modelHours = [18,19]  #commensurate with model_file_filter\n",
    "    for modelHour in modelHours:\n",
    "        obs_legStrs.append('Obs-{:d}Z'.format(modelHour))\n",
    "        mod_legStrs.append('Mod-{:d}Z'.format(modelHour))\n",
    "        datetimeStrs.append('2013-11-08 {:2d}:00:00.00'.format(modelHour))\n",
    "    print(obs_legStrs)\n",
    "    print(mod_legStrs)\n",
    "    print(datetimeStrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tslist needs to be parsed by x and y (instead of z) due to time it takes to read all dask chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compare_to_obs:\n",
    "    if model_data_type == 'ts': \n",
    "        del ds\n",
    "        ds=xr.open_mfdataset(modelprocessedname,concat_dim='datetime',combine='nested',chunks={'nx': 10, 'ny': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compare_to_obs:\n",
    "    fntSize=16\n",
    "    plt.rcParams['xtick.labelsize']=fntSize\n",
    "    plt.rcParams['ytick.labelsize']=fntSize\n",
    "    numPlotsX = 1\n",
    "    numPlotsY = 4\n",
    "    colors = []\n",
    "    #colors.append([0.25,0.25,0.75])\n",
    "    colors.append([0.35,0.45,0.75])\n",
    "    colors.append([0.75,0.45,0.35])\n",
    "    fig,ax = plt.subplots(numPlotsX,numPlotsY,sharey=True,sharex=False,figsize=(30,10))\n",
    "    iLoc = iLocs[7]\n",
    "    # plot-windspeed\n",
    "    for it in range(len(modelHours)): \n",
    "        if 'datetime' in ds['z'].dims:\n",
    "            if model_data_type == 'wrfout':   zValues = ds['z'].sel(datetime=datetimeStrs[it],ny=0,nx=iLoc)\n",
    "            elif model_data_type == 'ts': zValues = ds['z'].sel(ny=0,nx=iLoc).sel(datetime=datetimeStrs[it]).isel(datetime=0)\n",
    "        else:\n",
    "            zValues = ds['z']\n",
    "        # plot-windspeed\n",
    "        im = ax[0].plot(df30['wspd'].loc[datetimeStrs[it]],df30['height'].loc[datetimeStrs[it]],'*--',color=colors[it],label=obs_legStrs[it])\n",
    "        if model_data_type == 'wrfout':\n",
    "            im = ax[0].plot(ds['UMean'].sel(nx=iLoc,nz=range(ds.dims['nz'])).resample({'datetime':'30min'}).mean(dim='datetime').sel(datetime=datetimeStrs[it]),\n",
    "                            zValues,\n",
    "                            'o-',color=colors[it],markerfacecolor=\"None\",label=mod_legStrs[it])\n",
    "        elif model_data_type == 'ts':\n",
    "            im = ax[0].plot(ds['UMean'].sel(nx=iLoc,ny=0,nz=range(ds.dims['nz']-1)).resample({'datetime':'30min'}).mean(dim='datetime').sel(datetime=datetimeStrs[it]),\n",
    "                            zValues[:-1],\n",
    "                            'o-',color=colors[it],markerfacecolor=\"None\",label=mod_legStrs[it])\n",
    "        # plot-wind_dir.\n",
    "        im = ax[1].plot(df30['wdir'].loc[datetimeStrs[it]],df30['height'].loc[datetimeStrs[it]],'*--',color=colors[it],label=obs_legStrs[it])\n",
    "        if model_data_type == 'wrfout':\n",
    "            im = ax[1].plot(ds['UdirMean'].sel(nx=iLoc,nz=range(ds.dims['nz'])).resample({'datetime':'30min'}).mean(dim='datetime').sel(datetime=datetimeStrs[it]),\n",
    "                            zValues,\n",
    "                            'o-',color=colors[it],markerfacecolor=\"None\",label=mod_legStrs[it])\n",
    "        elif model_data_type == 'ts':\n",
    "            im = ax[1].plot(ds['UdirMean'].sel(nx=iLoc,ny=0,nz=range(ds.dims['nz']-1)).resample({'datetime':'30min'}).mean(dim='datetime').sel(datetime=datetimeStrs[it]),\n",
    "                            zValues[:-1],\n",
    "                            'o-',color=colors[it],markerfacecolor=\"None\",label=mod_legStrs[it])\n",
    "        # plot-theta\n",
    "        im = ax[2].plot(df30['theta'].loc[datetimeStrs[it]],df30['height'].loc[datetimeStrs[it]],'*--',color=colors[it],label=obs_legStrs[it])\n",
    "        if model_data_type == 'wrfout':\n",
    "            im = ax[2].plot(ds['thetaMean'].sel(nx=iLoc,nz=range(ds.dims['nz'])).resample({'datetime':'30min'}).mean(dim='datetime').sel(datetime=datetimeStrs[it]),\n",
    "                            zValues,\n",
    "                            'o-',color=colors[it],markerfacecolor=\"None\",label=mod_legStrs[it])\n",
    "        elif model_data_type == 'ts':\n",
    "            im = ax[2].plot(ds['thetaMean'].sel(nx=iLoc,ny=0,nz=range(ds.dims['nz']-1)).resample({'datetime':'30min'}).mean(dim='datetime').sel(datetime=datetimeStrs[it]),\n",
    "                            zValues[:-1],\n",
    "                            'o-',color=colors[it],markerfacecolor=\"None\",label=mod_legStrs[it])\n",
    "        # plot-w\n",
    "        im = ax[3].plot(df30['w'].loc[datetimeStrs[it]],df30['height'].loc[datetimeStrs[it]],'*--',color=colors[it],label=obs_legStrs[it])\n",
    "        if model_data_type == 'wrfout':\n",
    "            im = ax[3].plot(ds['wMean'].sel(nx=iLoc,nz=range(ds.dims['nz'])).resample({'datetime':'30min'}).mean(dim='datetime').sel(datetime=datetimeStrs[it]),\n",
    "                            zValues,\n",
    "                            'o-',color=colors[it],markerfacecolor=\"None\",label=mod_legStrs[it])\n",
    "        elif model_data_type == 'ts':        \n",
    "            im = ax[3].plot(ds['wMean'].sel(nx=iLoc,ny=0,nz=range(ds.dims['nz']-1)).resample({'datetime':'30min'}).mean(dim='datetime').sel(datetime=datetimeStrs[it]),\n",
    "                            zValues[:-1],\n",
    "                            'o-',color=colors[it],markerfacecolor=\"None\",label=mod_legStrs[it])\n",
    "    #ax[0].set_ylim([0,1700])\n",
    "    #ax[0].set_xlim([5,18.5])\n",
    "\n",
    "    ax[0].set_ylim([0,205])\n",
    "    ax[0].set_xlim([5,12.5])\n",
    "    ax[1].set_xlim([180,295])\n",
    "    ax[2].set_xlim([292,300])\n",
    "    ax[3].set_xlim([-0.25,0.25])\n",
    "\n",
    "    ax[0].legend(fontsize=12)\n",
    "    ax[0].set_xlabel(r'$U$ $[\\mathrm{ms^{-1}}]$',fontsize=fntSize)\n",
    "    ax[0].minorticks_on()\n",
    "    ax[0].grid(which='both')\n",
    "\n",
    "    ax[1].set_xlabel(r'$dir$ $[\\mathrm{\\circ}]$',fontsize=fntSize)\n",
    "    ax[1].minorticks_on()\n",
    "    ax[1].grid(which='both')\n",
    "\n",
    "    ax[2].set_xlabel(r'$\\theta$ $[\\mathrm{K}]$',fontsize=fntSize)\n",
    "    ax[2].minorticks_on()\n",
    "    ax[2].grid(which='both')\n",
    "\n",
    "    ax[3].set_xlabel(r'$w$ $[\\mathrm{ms^{-1}}]$',fontsize=fntSize)\n",
    "    ax[3].minorticks_on()\n",
    "    ax[3].grid(which='both')\n",
    "    if save_figs:\n",
    "        print(output_obscomp)\n",
    "        fig.savefig(output_obscomp,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyhawbeck",
   "language": "python",
   "name": "pyhawbeck"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
